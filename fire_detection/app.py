import os
import io
from tempfile import NamedTemporaryFile
from typing import Optional

import cv2
import numpy as np
from PIL import Image
import streamlit as st
import requests

try:
    from ultralytics import YOLO
except Exception as e:  # pragma: no cover
    YOLO = None


st.set_page_config(page_title="Ph√°t hi·ªán l·ª≠a - YOLOv8", page_icon="üî•", layout="wide")
st.title("üî• Ph√°t hi·ªán l·ª≠a (YOLOv8)")
st.caption("T·∫£i ·∫£nh/video ho·∫∑c ch·ª•p ·∫£nh ƒë·ªÉ ch·∫°y m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán.")

# -------------------- Sidebar --------------------
st.sidebar.header("C·∫•u h√¨nh m√¥ h√¨nh")

WEIGHTS_FIXED_PATH = "/workspace/ai_intern/PHAT/fire_detection/runs/detect/train2/weights/best.pt"
st.sidebar.info(f"Tr·ªçng s·ªë c·ªë ƒë·ªãnh: {WEIGHTS_FIXED_PATH}")

confidence = st.sidebar.slider("ƒê·ªô tin c·∫≠y (confidence)", 0.0, 1.0, 0.5, 0.01)
iou = st.sidebar.slider("Ng∆∞·ª°ng IoU", 0.0, 1.0, 0.45, 0.01)

device = st.sidebar.selectbox("Thi·∫øt b·ªã", ["auto", "cpu", "cuda"], index=0)

st.sidebar.markdown("---")
st.sidebar.header("Ngu·ªìn d·ªØ li·ªáu")
source_type = st.sidebar.radio(
    "Ch·ªçn ngu·ªìn",
    ["·∫¢nh", "Video", "Webcam (ch·ª•p ·∫£nh)"],
    index=0,
)

# -------------------- Helpers --------------------
@st.cache_resource(show_spinner=False)
def load_model(weights_file_path: str):
    if YOLO is None:
        raise RuntimeError("Ultralytics YOLO ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. H√£y c√†i ƒë·∫∑t b·∫±ng: pip install ultralytics")
    return YOLO(weights_file_path)


def ensure_uploaded_weights_to_path(uploaded) -> Optional[str]:
    if uploaded is None:
        return None
    suffix = os.path.splitext(uploaded.name)[1] or ".pt"
    tmp = NamedTemporaryFile(delete=False, suffix=suffix)
    tmp.write(uploaded.read())
    tmp.flush()
    tmp.close()
    return tmp.name


def annotate_image_array(image_bgr: np.ndarray, model) -> np.ndarray:
    results = model.predict(
        source=image_bgr,
        conf=confidence,
        iou=iou,
        device=device,
        verbose=False,
    )
    annotated = results[0].plot()  # BGR ndarray
    return annotated


def pil_to_bgr(img: Image.Image) -> np.ndarray:
    rgb = np.array(img.convert("RGB"))
    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
    return bgr


def bgr_to_rgb_img(bgr: np.ndarray) -> Image.Image:
    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb)


def load_image_from_url(url: str) -> Image.Image:
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    return Image.open(io.BytesIO(resp.content)).convert("RGB")


# -------------------- Resolve weights --------------------
resolved_weights_path: Optional[str] = WEIGHTS_FIXED_PATH

model = None
if resolved_weights_path and os.path.exists(resolved_weights_path):
    with st.spinner("ƒêang t·∫£i m√¥ h√¨nh..."):
        try:
            model = load_model(resolved_weights_path)
            st.success(f"ƒê√£ t·∫£i m√¥ h√¨nh t·ª´: {resolved_weights_path}")
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh: {e}")
else:
    st.error(
        f"Kh√¥ng t√¨m th·∫•y t·ªáp tr·ªçng s·ªë t·∫°i: {WEIGHTS_FIXED_PATH}"
    )

# -------------------- Main content --------------------
col_left, col_right = st.columns([1, 1])

if source_type == "·∫¢nh":
    with col_left:
        image_source_mode = st.radio("Ngu·ªìn ·∫£nh", ["T·∫£i t·ªáp", "URL"], index=0)
        img = None
        image_url = ""
        if image_source_mode == "T·∫£i t·ªáp":
            img_file = st.file_uploader(
                "T·∫£i ·∫£nh", type=["jpg", "jpeg", "png", "bmp", "webp"], accept_multiple_files=False
            )
            if img_file is not None:
                img = Image.open(img_file)
        else:
            image_url = st.text_input("Nh·∫≠p URL ·∫£nh (http/https)")
            if image_url:
                try:
                    img = load_image_from_url(image_url)
                except Exception as e:
                    st.error(f"Kh√¥ng t·∫£i ƒë∆∞·ª£c ·∫£nh t·ª´ URL: {e}")
        run_btn = st.button("Ch·∫°y nh·∫≠n d·∫°ng")

    if img is not None:
        col_left.image(img, caption="·∫¢nh g·ªëc", use_container_width=True)

    if run_btn and img is not None and model is not None:
        bgr = pil_to_bgr(img)
        with st.spinner("ƒêang suy lu·∫≠n..."):
            annotated_bgr = annotate_image_array(bgr, model)
        annotated_img = bgr_to_rgb_img(annotated_bgr)

        with col_right:
            st.image(annotated_img, caption="K·∫øt qu·∫£", use_container_width=True)

            buf = io.BytesIO()
            annotated_img.save(buf, format="PNG")
            byte_im = buf.getvalue()
            st.download_button(
                label="T·∫£i ·∫£nh k·∫øt qu·∫£",
                data=byte_im,
                file_name="prediction.png",
                mime="image/png",
            )

elif source_type == "Video":
    with col_left:
        vid_file = st.file_uploader(
            "T·∫£i video", type=["mp4", "mov", "avi", "mkv", "webm"], accept_multiple_files=False
        )
        run_btn = st.button("X·ª≠ l√Ω video")

    if run_btn and vid_file is not None and model is not None:
        # L∆∞u video ngu·ªìn ra file t·∫°m
        src_tmp = NamedTemporaryFile(delete=False, suffix=os.path.splitext(vid_file.name)[1])
        src_tmp.write(vid_file.read())
        src_tmp.flush()
        src_tmp.close()

        cap = cv2.VideoCapture(src_tmp.name)
        if not cap.isOpened():
            st.error("Kh√¥ng th·ªÉ m·ªü video.")
        else:
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
            fps = cap.get(cv2.CAP_PROP_FPS) or 25
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            out_tmp = NamedTemporaryFile(delete=False, suffix=".mp4")
            out_path = out_tmp.name
            out_tmp.close()

            fourcc = cv2.VideoWriter_fourcc(*"mp4v")
            writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

            progress = st.progress(0)
            status = st.empty()

            frame_idx = 0
            with st.spinner("ƒêang x·ª≠ l√Ω video..."):
                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    annotated = annotate_image_array(frame, model)
                    writer.write(annotated)

                    frame_idx += 1
                    if total > 0:
                        progress.progress(min(frame_idx / total, 1.0))
                    if frame_idx % max(int(fps // 2), 1) == 0:
                        status.image(
                            bgr_to_rgb_img(annotated), caption=f"X·ª≠ l√Ω khung {frame_idx}/{total}", use_container_width=True
                        )

            cap.release()
            writer.release()

            with col_right:
                st.success("Ho√†n t·∫•t x·ª≠ l√Ω.")
                st.video(out_path)
                with open(out_path, "rb") as f:
                    st.download_button(
                        label="T·∫£i video k·∫øt qu·∫£",
                        data=f.read(),
                        file_name="prediction.mp4",
                        mime="video/mp4",
                    )

elif source_type == "Webcam (ch·ª•p ·∫£nh)":
    with col_left:
        shot = st.camera_input("Ch·ª•p ·∫£nh t·ª´ webcam")
        run_btn = st.button("Nh·∫≠n d·∫°ng ·∫£nh ch·ª•p")

    if run_btn and shot is not None and model is not None:
        img = Image.open(shot)
        bgr = pil_to_bgr(img)
        with st.spinner("ƒêang suy lu·∫≠n..."):
            annotated_bgr = annotate_image_array(bgr, model)
        annotated_img = bgr_to_rgb_img(annotated_bgr)

        with col_right:
            st.image(annotated_img, caption="K·∫øt qu·∫£", use_container_width=True)
            buf = io.BytesIO()
            annotated_img.save(buf, format="PNG")
            st.download_button(
                label="T·∫£i ·∫£nh k·∫øt qu·∫£",
                data=buf.getvalue(),
                file_name="prediction.png",
                mime="image/png",
            )

